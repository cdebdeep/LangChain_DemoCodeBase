{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Built IN Tools\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/tools/\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are interfaces that an agent, chain, or LLM can use to interact with the world. \\\n",
    "It is useful to have all this information because this information can be used to build action-taking systems! \n",
    "\n",
    "They combine a few things: \n",
    "\n",
    "The name of the tool \\\n",
    "A description of what the tool is \\\n",
    "JSON schema of what the inputs to the tool are \\\n",
    "The function to call \\\n",
    "Whether the result of a tool should be returned directly to the user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we need a Tool !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HelperAIKey import fnc_getOpenAIKey , fnc_getTavilyKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key='Your API Key Here', verbose=True)  # Put your openAI key here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke('Tell me on cyclone remal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duck Duck Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_duckDuckGo_Tool =DuckDuckGoSearchRun()\n",
    "_duckDuckGo_Tool.run(\"Tell me on cyclone remal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_duckDuckGo_Tool =DuckDuckGoSearchResults()\n",
    "_duckDuckGo_Tool.run(\"Tell me on cyclone remal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name : ' + _duckDuckGo_Tool.name)\n",
    "print('Description : ' + _duckDuckGo_Tool.description)\n",
    "print('Args : ' + str(_duckDuckGo_Tool.args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "tools=[_duckDuckGo_Tool]\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"), \n",
    "    (\"human\", \"{input}\"), \n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "llm.bind_tools([_duckDuckGo_Tool])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools,handle_parsing_errors=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Tell me on cyclone remal\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tavily Search\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/tavily_search/\n",
    "\n",
    "Tavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = 'Your API Key Here'\n",
    "_tavily_tool = TavilySearchResults()\n",
    "\n",
    "_tavily_tool.invoke({\"query\": \"Tell me on cyclone remal\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "tools=[_tavily_tool]\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"), \n",
    "    (\"human\", \"{input}\"), \n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "llm.bind_tools([_tavily_tool])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools,handle_parsing_errors=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Tell me on cyclone remal\", })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both the Tools !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "tools=[_duckDuckGo_Tool,_tavily_tool]\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"), \n",
    "    (\"human\", \"{input}\"), \n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "llm.bind_tools([_duckDuckGo_Tool,_tavily_tool])\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools,handle_parsing_errors=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"Tell me on cyclone remal\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
